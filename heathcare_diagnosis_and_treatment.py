# -*- coding: utf-8 -*-
"""heathcare-diagnosis-and-treatment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/divya-160106/c48defe785f62fcf381471323479574f/heathcare-diagnosis-and-treatment.ipynb
"""

!pip install speechrecognition librosa numpy nltk pydub

import nltk
import numpy as np
import random
import speech_recognition as sr
import librosa
import os
from pydub import AudioSegment
from IPython.display import Audio

# Download NLTK data
nltk.download('vader_lexicon')
from nltk.sentiment import SentimentIntensityAnalyzer
sia = SentimentIntensityAnalyzer()

# CBT Responses
CBT_RESPONSES = {
    'positive': [
        "Keep up the good energy! Consider journaling to maintain your mood.",
        "You're doing great. Try sharing your joy with someone today."
    ],
    'neutral': [
        "Take a deep breath. Reflecting on your thoughts can bring clarity.",
        "It's okay to feel neutral. Try identifying one small thing you're grateful for."
    ],
    'negative': [
        "It's okay to feel down. Consider doing a grounding exercise like 5-4-3-2-1.",
        "Remember, this feeling will pass. Try writing down what's bothering you and challenge those thoughts."
    ]
}

def classify_text_emotion(text):
    sentiment = sia.polarity_scores(text)
    compound = sentiment['compound']
    if compound >= 0.3:
        return 'positive'
    elif compound <= -0.3:
        return 'negative'
    else:
        return 'neutral'

def analyze_audio_emotion(file_path):
    y, sr = librosa.load(file_path, duration=5)
    pitch = librosa.yin(y, fmin=50, fmax=300, sr=sr)
    energy = np.mean(librosa.feature.rms(y=y))

    if np.std(pitch) > 50 and energy < 0.01:
        return 'negative'
    return 'neutral'

from google.colab import files
uploaded = files.upload()

print("Uploaded files:", uploaded)

wav_path = None

for fname in uploaded:
    print(f"Processing file: {fname}")
    if fname.endswith(".mp3"):
        sound = AudioSegment.from_mp3(fname)
        wav_path = fname.replace(".mp3", ".wav")
        sound.export(wav_path, format="wav")
    elif fname.endswith(".wav"):
        wav_path = fname

if wav_path is None:
    raise ValueError("No audio file uploaded or unsupported file format!")

print(f"File to process: {wav_path}")

def detect_emotion_and_respond(audio_path):
    recognizer = sr.Recognizer()
    text = ""

    with sr.AudioFile(audio_path) as source:
        audio = recognizer.record(source)
        try:
            text = recognizer.recognize_google(audio)
        except sr.UnknownValueError:
            text = "[Unrecognizable Speech]"

    text_emotion = classify_text_emotion(text)
    audio_emotion = analyze_audio_emotion(audio_path)

    final_emotion = 'negative' if 'negative' in [text_emotion, audio_emotion] else text_emotion
    response = random.choice(CBT_RESPONSES[final_emotion])

    return {
        "transcribed_text": text,
        "text_emotion": text_emotion,
        "audio_emotion": audio_emotion,
        "final_emotion": final_emotion,
        "cbt_response": response
    }

result = detect_emotion_and_respond(wav_path)

for key, value in result.items():
    print(f"{key.capitalize().replace('_', ' ')}: {value}")